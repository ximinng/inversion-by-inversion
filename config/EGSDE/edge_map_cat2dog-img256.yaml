seed: 1234
# data
dataset: "cat2dog"
num_classes: 2
image_size: 256
channels: 3
# optimizer
lr: 3e-4
adam_betas: [ 0.9, 0.999 ]
weight_decay: 0.05
lr_scheduler: "cosine" # "linear", "cosine" ,"cosine_with_restarts", "constant_with_warmup"
lr_warmup_steps: 100
# train:
train_num_steps: 700000
train_batch_size: 32
noised: True
schedule_sampler: "uniform"
# sample
valid_batch_size: 8
# methods
perturb_step: 500
repeat_step: 1 # K

expert:
  lam_s: 100
  lam_i: 0.01
  s1: "cosine"
  s2: "neg_l2"
  down_N: 32

model:
  type: "ADM"
  use_fp16: False
  in_channels: 3
  num_channels: 128
  out_channels: 3
  num_res_blocks: 1
  class_cond: False
  use_checkpoint: False
  attention_resolutions: "16"
  num_heads: 4
  num_head_channels: 64
  num_heads_upsample: -1
  use_scale_shift_norm: True
  dropout: 0
  resblock_updown: True
  use_new_attention_order: False

diffusion:
  beta_schedule: "linear"
  beta_start: 0.0001
  beta_end: 0.02
  timesteps: 1000
  var_type: fixedsmall # here
  clip_denoised: True
  learn_sigma: True # out_channels * 2
  sigma_small: False
  use_kl: False
  predict_xstart: False
  rescale_timesteps: False
  rescale_learned_sigmas: False
  use_ddim: False
  timestep_respacing: ""

dse:
  load_share_weights: True
  use_fp16: False
  model_channels: 128 # width
  num_res_blocks: 2 # depth
  attention_resolutions: '32,16,8'
  use_scale_shift_norm: True
  resblock_updown: True
  pool: 'attention'
